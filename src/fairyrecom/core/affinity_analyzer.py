# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import sqlite3
import json
import re
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from textblob import TextBlob
import warnings
import logging
from rich.logging import RichHandler
from rich.console import Console
warnings.filterwarnings('ignore')

# é…ç½®Rich logging
console = Console()
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    handlers=[RichHandler(console=console, rich_tracebacks=True)]
)
logger = logging.getLogger(__name__)

class VideoAffinityAnalyzer:
    """
    è§†é¢‘å–œçˆ±åº¦åˆ†æå™¨
    
    åŠŸèƒ½:
    1. åŠ è½½ç”¨æˆ·-è§†é¢‘äº¤äº’æ•°æ®
    2. è®¡ç®—å¤šç»´åº¦å–œçˆ±åº¦åˆ†æ•°
    3. å­˜å‚¨åˆ†æç»“æœåˆ°SQLiteæ•°æ®åº“
    4. æä¾›æŸ¥è¯¢å’Œç»Ÿè®¡åŠŸèƒ½
    """
    
    def __init__(self, db_path: str = "data.db"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            db_path: SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        self.db_path = db_path
        self.data = None
        self.affinity_scores = {}
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
    
    def _init_database(self):
        """
        åˆå§‹åŒ–SQLiteæ•°æ®åº“å’Œè¡¨ç»“æ„
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºç”¨æˆ·è§†é¢‘å–œçˆ±åº¦è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_video_affinity (
                user_id INTEGER NOT NULL,
                video_id INTEGER NOT NULL,
                affinity_score REAL CHECK (affinity_score BETWEEN 0 AND 1),
                rating_score REAL,
                like_score REAL,
                sentiment_score REAL,
                engagement_score REAL,
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                PRIMARY KEY (user_id, video_id)
            )
        """)
        
        # åˆ›å»ºè§†é¢‘ç»Ÿè®¡è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS video_statistics (
                video_id INTEGER PRIMARY KEY,
                total_users INTEGER,
                avg_affinity_score REAL,
                avg_rating REAL,
                like_rate REAL,
                avg_sentiment REAL,
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # åˆ›å»ºç”¨æˆ·ç»Ÿè®¡è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_statistics (
                user_id INTEGER PRIMARY KEY,
                total_videos INTEGER,
                avg_affinity_score REAL,
                avg_rating REAL,
                like_rate REAL,
                avg_sentiment REAL,
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.commit()
        conn.close()
        logger.info(f"[green]æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}[/green]")
    
    def load_data(self, file_path: str = "reasoner/dataset/dataset/interaction.csv") -> pd.DataFrame:
        """
        åŠ è½½ç”¨æˆ·-è§†é¢‘äº¤äº’æ•°æ®
        
        Args:
            file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŠ è½½çš„æ•°æ®DataFrame
        """
        try:
            # å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦
            for sep in ['\t', ',', ';']:
                try:
                    self.data = pd.read_csv(file_path, sep=sep)
                    if len(self.data.columns) > 5:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                        break
                except:
                    continue
            
            if self.data is None:
                raise ValueError("æ— æ³•è¯»å–æ•°æ®æ–‡ä»¶")
            
            logger.info(f"[green]æ•°æ®åŠ è½½æˆåŠŸï¼Œå…±{len(self.data)}æ¡è®°å½•[/green]")
            logger.info(f"[cyan]æ•°æ®åˆ—: {list(self.data.columns)}[/cyan]")
            
            # æ•°æ®é¢„å¤„ç†
            self._preprocess_data()
            
            return self.data
            
        except Exception as e:
            logger.error(f"[red]æ•°æ®åŠ è½½å¤±è´¥: {e}[/red]")
            raise
    
    def _preprocess_data(self):
        """
        æ•°æ®é¢„å¤„ç†
        """
        # å¤„ç†ç¼ºå¤±å€¼
        self.data['rating'] = pd.to_numeric(self.data['rating'], errors='coerce')
        self.data['like'] = pd.to_numeric(self.data['like'], errors='coerce')
        
        # å¡«å……ç¼ºå¤±å€¼
        self.data['rating'].fillna(self.data['rating'].mean(), inplace=True)
        self.data['like'].fillna(0, inplace=True)
        self.data['review'].fillna('', inplace=True)
        
        logger.info("[green]æ•°æ®é¢„å¤„ç†å®Œæˆ[/green]")
    
    def calculate_sentiment_score(self, text: str) -> float:
        """
        è®¡ç®—æ–‡æœ¬æƒ…æ„Ÿåˆ†æ•°
        
        Args:
            text: è¯„è®ºæ–‡æœ¬
            
        Returns:
            æƒ…æ„Ÿåˆ†æ•° (0-1)
        """
        if not text or pd.isna(text):
            return 0.5  # ä¸­æ€§
        
        try:
            # ä½¿ç”¨TextBlobè¿›è¡Œæƒ…æ„Ÿåˆ†æ
            blob = TextBlob(str(text))
            sentiment = blob.sentiment.polarity
            
            # å°†æƒ…æ„Ÿåˆ†æ•°ä»[-1,1]æ˜ å°„åˆ°[0,1]
            return (sentiment + 1) / 2
        except:
            # ç®€å•çš„å…³é”®è¯æƒ…æ„Ÿåˆ†æä½œä¸ºå¤‡é€‰
            positive_words = ['like', 'love', 'good', 'great', 'excellent', 'amazing', 'wonderful', 
                            'å–œæ¬¢', 'çˆ±', 'å¥½', 'æ£’', 'ä¼˜ç§€', 'ç²¾å½©', 'æœ‰è¶£']
            negative_words = ['hate', 'bad', 'terrible', 'awful', 'boring', 'stupid',
                            'è®¨åŒ', 'å', 'ç³Ÿç³•', 'æ— èŠ', 'æ„šè ¢', 'å·®']
            
            text_lower = str(text).lower()
            positive_count = sum(1 for word in positive_words if word in text_lower)
            negative_count = sum(1 for word in negative_words if word in text_lower)
            
            if positive_count + negative_count == 0:
                return 0.5
            
            return positive_count / (positive_count + negative_count)
    
    def calculate_engagement_score(self, row) -> float:
        """
        è®¡ç®—ç”¨æˆ·å‚ä¸åº¦åˆ†æ•°
        
        Args:
            row: æ•°æ®è¡Œ
            
        Returns:
            å‚ä¸åº¦åˆ†æ•° (0-1)
        """
        score = 0.0
        
        # è¯„è®ºé•¿åº¦è´¡çŒ®
        review_length = len(str(row.get('review', '')))
        if review_length > 0:
            score += min(review_length / 100, 0.3)  # æœ€å¤šè´¡çŒ®0.3åˆ†
        
        # æ ‡ç­¾æ•°é‡è´¡çŒ®
        for tag_col in ['reason_tag', 'video_tag', 'interest_tag']:
            if tag_col in row and pd.notna(row[tag_col]):
                try:
                    tags = eval(str(row[tag_col])) if isinstance(row[tag_col], str) else row[tag_col]
                    if isinstance(tags, list):
                        score += min(len(tags) / 10, 0.2)  # æ¯ä¸ªæ ‡ç­¾åˆ—æœ€å¤šè´¡çŒ®0.2åˆ†
                except:
                    pass
        
        # æ˜¯å¦æ„¿æ„å†æ¬¡è§‚çœ‹
        if 'watch_again' in row and row['watch_again'] == 1:
            score += 0.3
        
        return min(score, 1.0)
    
    def calculate_affinity_score(self, row) -> Dict[str, float]:
        """
        è®¡ç®—ç»¼åˆå–œçˆ±åº¦åˆ†æ•°
        
        Args:
            row: æ•°æ®è¡Œ
            
        Returns:
            åŒ…å«å„ç»´åº¦åˆ†æ•°çš„å­—å…¸
        """
        # è¯„åˆ†åˆ†æ•° (1-5 -> 0-1)
        rating_score = (row['rating'] - 1) / 4 if pd.notna(row['rating']) else 0.5
        
        # ç‚¹èµåˆ†æ•°
        like_score = float(row['like']) if pd.notna(row['like']) else 0.0
        
        # æƒ…æ„Ÿåˆ†æ•°
        sentiment_score = self.calculate_sentiment_score(row.get('review', ''))
        
        # å‚ä¸åº¦åˆ†æ•°
        engagement_score = self.calculate_engagement_score(row)
        
        # ç»¼åˆå–œçˆ±åº¦åˆ†æ•° (åŠ æƒå¹³å‡)
        weights = {
            'rating': 0.3,
            'like': 0.25,
            'sentiment': 0.25,
            'engagement': 0.2
        }
        
        affinity_score = (
            weights['rating'] * rating_score +
            weights['like'] * like_score +
            weights['sentiment'] * sentiment_score +
            weights['engagement'] * engagement_score
        )
        
        return {
            'affinity_score': affinity_score,
            'rating_score': rating_score,
            'like_score': like_score,
            'sentiment_score': sentiment_score,
            'engagement_score': engagement_score
        }
    
    def analyze_all_users(self) -> Dict[Tuple[int, int], Dict[str, float]]:
        """
        åˆ†ææ‰€æœ‰ç”¨æˆ·çš„è§†é¢‘å–œçˆ±åº¦
        
        Returns:
            ç”¨æˆ·-è§†é¢‘å–œçˆ±åº¦åˆ†æ•°å­—å…¸
        """
        if self.data is None:
            raise ValueError("è¯·å…ˆåŠ è½½æ•°æ®")
        
        logger.info("[yellow]å¼€å§‹åˆ†æç”¨æˆ·è§†é¢‘å–œçˆ±åº¦...[/yellow]")
        
        affinity_results = {}
        
        for idx, row in self.data.iterrows():
            user_id = int(row['user_id'])
            video_id = int(row['video_id'])
            
            scores = self.calculate_affinity_score(row)
            affinity_results[(user_id, video_id)] = scores
            
            if (idx + 1) % 1000 == 0:
                logger.info(f"[cyan]å·²å¤„ç† {idx + 1} æ¡è®°å½•[/cyan]")
        
        self.affinity_scores = affinity_results
        logger.info(f"[green]åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(affinity_results)} ä¸ªç”¨æˆ·-è§†é¢‘å¯¹[/green]")
        
        return affinity_results
    
    def save_to_database(self, batch_size: int = 1000):
        """
        å°†åˆ†æç»“æœä¿å­˜åˆ°æ•°æ®åº“
        
        Args:
            batch_size: æ‰¹é‡æ’å…¥å¤§å°
        """
        if not self.affinity_scores:
            raise ValueError("è¯·å…ˆè¿›è¡Œå–œçˆ±åº¦åˆ†æ")
        
        logger.info("[yellow]å¼€å§‹ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...[/yellow]")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ¸…ç©ºæ—§æ•°æ®
        cursor.execute("DELETE FROM user_video_affinity")
        
        # æ‰¹é‡æ’å…¥æ•°æ®
        batch_data = []
        for (user_id, video_id), scores in self.affinity_scores.items():
            batch_data.append((
                user_id,
                video_id,
                scores['affinity_score'],
                scores['rating_score'],
                scores['like_score'],
                scores['sentiment_score'],
                scores['engagement_score'],
                datetime.now()
            ))
            
            if len(batch_data) >= batch_size:
                cursor.executemany("""
                    INSERT OR REPLACE INTO user_video_affinity 
                    (user_id, video_id, affinity_score, rating_score, like_score, 
                     sentiment_score, engagement_score, last_updated)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, batch_data)
                batch_data = []
        
        # æ’å…¥å‰©ä½™æ•°æ®
        if batch_data:
            cursor.executemany("""
                INSERT OR REPLACE INTO user_video_affinity 
                (user_id, video_id, affinity_score, rating_score, like_score, 
                 sentiment_score, engagement_score, last_updated)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, batch_data)
        
        conn.commit()
        
        # æ›´æ–°ç»Ÿè®¡è¡¨
        self._update_statistics(cursor)
        
        conn.commit()
        conn.close()
        
        logger.info(f"[green]æ•°æ®ä¿å­˜å®Œæˆï¼Œå…±ä¿å­˜ {len(self.affinity_scores)} æ¡è®°å½•[/green]")
    
    def _update_statistics(self, cursor):
        """
        æ›´æ–°ç»Ÿè®¡è¡¨
        """
        logger.info("[yellow]æ›´æ–°ç»Ÿè®¡ä¿¡æ¯...[/yellow]")
        
        # æ›´æ–°è§†é¢‘ç»Ÿè®¡
        cursor.execute("""
            INSERT OR REPLACE INTO video_statistics 
            (video_id, total_users, avg_affinity_score, avg_rating, like_rate, avg_sentiment, last_updated)
            SELECT 
                video_id,
                COUNT(*) as total_users,
                AVG(affinity_score) as avg_affinity_score,
                AVG(rating_score) as avg_rating,
                AVG(like_score) as like_rate,
                AVG(sentiment_score) as avg_sentiment,
                datetime('now') as last_updated
            FROM user_video_affinity
            GROUP BY video_id
        """)
        
        # æ›´æ–°ç”¨æˆ·ç»Ÿè®¡
        cursor.execute("""
            INSERT OR REPLACE INTO user_statistics 
            (user_id, total_videos, avg_affinity_score, avg_rating, like_rate, avg_sentiment, last_updated)
            SELECT 
                user_id,
                COUNT(*) as total_videos,
                AVG(affinity_score) as avg_affinity_score,
                AVG(rating_score) as avg_rating,
                AVG(like_score) as like_rate,
                AVG(sentiment_score) as avg_sentiment,
                datetime('now') as last_updated
            FROM user_video_affinity
            GROUP BY user_id
        """)
    
    def get_user_affinity(self, user_id: int, limit: int = 10) -> List[Tuple]:
        """
        è·å–ç”¨æˆ·çš„è§†é¢‘å–œçˆ±åº¦æ’è¡Œ
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            è§†é¢‘å–œçˆ±åº¦åˆ—è¡¨
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT video_id, affinity_score, rating_score, like_score, sentiment_score, engagement_score
            FROM user_video_affinity
            WHERE user_id = ?
            ORDER BY affinity_score DESC
            LIMIT ?
        """, (user_id, limit))
        
        results = cursor.fetchall()
        conn.close()
        
        return results
    
    def get_video_affinity(self, video_id: int, limit: int = 10) -> List[Tuple]:
        """
        è·å–è§†é¢‘çš„ç”¨æˆ·å–œçˆ±åº¦æ’è¡Œ
        
        Args:
            video_id: è§†é¢‘ID
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            ç”¨æˆ·å–œçˆ±åº¦åˆ—è¡¨
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT user_id, affinity_score, rating_score, like_score, sentiment_score, engagement_score
            FROM user_video_affinity
            WHERE video_id = ?
            ORDER BY affinity_score DESC
            LIMIT ?
        """, (video_id, limit))
        
        results = cursor.fetchall()
        conn.close()
        
        return results
    
    def get_top_videos(self, limit: int = 10) -> List[Tuple]:
        """
        è·å–æœ€å—æ¬¢è¿çš„è§†é¢‘
        
        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            è§†é¢‘ç»Ÿè®¡åˆ—è¡¨
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT video_id, total_users, avg_affinity_score, avg_rating, like_rate, avg_sentiment
            FROM video_statistics
            ORDER BY avg_affinity_score DESC, total_users DESC
            LIMIT ?
        """, (limit,))
        
        results = cursor.fetchall()
        conn.close()
        
        return results
    
    def get_top_users(self, limit: int = 10) -> List[Tuple]:
        """
        è·å–æœ€æ´»è·ƒçš„ç”¨æˆ·
        
        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            ç”¨æˆ·ç»Ÿè®¡åˆ—è¡¨
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT user_id, total_videos, avg_affinity_score, avg_rating, like_rate, avg_sentiment
            FROM user_statistics
            ORDER BY total_videos DESC, avg_affinity_score DESC
            LIMIT ?
        """, (limit,))
        
        results = cursor.fetchall()
        conn.close()
        
        return results
    
    def generate_report(self, output_file: str = "video_affinity_report.txt"):
        """
        ç”Ÿæˆåˆ†ææŠ¥å‘Š
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        cursor.execute("SELECT COUNT(*) FROM user_video_affinity")
        total_records = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT user_id) FROM user_video_affinity")
        total_users = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(DISTINCT video_id) FROM user_video_affinity")
        total_videos = cursor.fetchone()[0]
        
        cursor.execute("SELECT AVG(affinity_score) FROM user_video_affinity")
        avg_affinity = cursor.fetchone()[0]
        
        conn.close()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""
è§†é¢‘å–œçˆ±åº¦åˆ†ææŠ¥å‘Š
{'='*50}

åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:
- æ€»è®°å½•æ•°: {total_records:,}
- ç”¨æˆ·æ•°é‡: {total_users:,}
- è§†é¢‘æ•°é‡: {total_videos:,}
- å¹³å‡å–œçˆ±åº¦: {avg_affinity:.4f}

æœ€å—æ¬¢è¿çš„è§†é¢‘ (Top 10):
{'è§†é¢‘ID':<10} {'ç”¨æˆ·æ•°':<8} {'å¹³å‡å–œçˆ±åº¦':<12} {'å¹³å‡è¯„åˆ†':<10} {'ç‚¹èµç‡':<8} {'æƒ…æ„Ÿåˆ†æ•°':<10}
{'-'*70}
"""
        
        top_videos = self.get_top_videos(10)
        for video_id, users, affinity, rating, like_rate, sentiment in top_videos:
            report += f"{video_id:<10} {users:<8} {affinity:<12.4f} {rating:<10.4f} {like_rate:<8.4f} {sentiment:<10.4f}\n"
        
        report += f"""

æœ€æ´»è·ƒçš„ç”¨æˆ· (Top 10):
{'ç”¨æˆ·ID':<10} {'è§†é¢‘æ•°':<8} {'å¹³å‡å–œçˆ±åº¦':<12} {'å¹³å‡è¯„åˆ†':<10} {'ç‚¹èµç‡':<8} {'æƒ…æ„Ÿåˆ†æ•°':<10}
{'-'*70}
"""
        
        top_users = self.get_top_users(10)
        for user_id, videos, affinity, rating, like_rate, sentiment in top_users:
            report += f"{user_id:<10} {videos:<8} {affinity:<12.4f} {rating:<10.4f} {like_rate:<8.4f} {sentiment:<10.4f}\n"
        
        report += f"""

åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æ•°æ®åº“æ–‡ä»¶: {self.db_path}
"""
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"[green]åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}[/green]")
        return report

def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºè§†é¢‘å–œçˆ±åº¦åˆ†ææµç¨‹
    """
    logger.info("[bold blue]è§†é¢‘å–œçˆ±åº¦åˆ†æç³»ç»Ÿ[/bold blue]")
    logger.info("[blue]=" * 40 + "[/blue]")
    
    try:
        # åˆ›å»ºåˆ†æå™¨
        analyzer = VideoAffinityAnalyzer()
        
        # åŠ è½½æ•°æ®
        data = analyzer.load_data()
        logger.info(f"\n[cyan]æ•°æ®æ¦‚è§ˆ:[/cyan]")
        logger.info(f"[white]- æ•°æ®å½¢çŠ¶: {data.shape}[/white]")
        logger.info(f"[white]- ç”¨æˆ·æ•°é‡: {data['user_id'].nunique()}[/white]")
        logger.info(f"[white]- è§†é¢‘æ•°é‡: {data['video_id'].nunique()}[/white]")
        logger.info(f"[white]- å¹³å‡è¯„åˆ†: {data['rating'].mean():.2f}[/white]")
        logger.info(f"[white]- ç‚¹èµç‡: {data['like'].mean():.2%}[/white]")
        
        # åˆ†æå–œçˆ±åº¦
        affinity_scores = analyzer.analyze_all_users()
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        analyzer.save_to_database()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = analyzer.generate_report()
        logger.info("\n" + "[blue]=" * 50 + "[/blue]")
        console.print(report)
        
        # ç¤ºä¾‹æŸ¥è¯¢
        logger.info("\n" + "[blue]=" * 50 + "[/blue]")
        logger.info("[yellow]ç¤ºä¾‹æŸ¥è¯¢:[/yellow]")
        
        # æŸ¥çœ‹ç”¨æˆ·2017çš„å–œçˆ±è§†é¢‘
        user_affinity = analyzer.get_user_affinity(2017, 5)
        logger.info(f"\n[cyan]ç”¨æˆ·2017æœ€å–œçˆ±çš„5ä¸ªè§†é¢‘:[/cyan]")
        for video_id, affinity, rating, like, sentiment, engagement in user_affinity:
            logger.info(f"[white]è§†é¢‘{video_id}: å–œçˆ±åº¦{affinity:.4f} (è¯„åˆ†{rating:.4f}, ç‚¹èµ{like:.4f}, æƒ…æ„Ÿ{sentiment:.4f}, å‚ä¸åº¦{engagement:.4f})[/white]")
        
        # æŸ¥çœ‹è§†é¢‘3539çš„ç”¨æˆ·å–œçˆ±åº¦
        video_affinity = analyzer.get_video_affinity(3539, 5)
        logger.info(f"\n[cyan]æœ€å–œçˆ±è§†é¢‘3539çš„5ä¸ªç”¨æˆ·:[/cyan]")
        for user_id, affinity, rating, like, sentiment, engagement in video_affinity:
            logger.info(f"[white]ç”¨æˆ·{user_id}: å–œçˆ±åº¦{affinity:.4f} (è¯„åˆ†{rating:.4f}, ç‚¹èµ{like:.4f}, æƒ…æ„Ÿ{sentiment:.4f}, å‚ä¸åº¦{engagement:.4f})[/white]")
        
        logger.info("\n[green]ğŸ‰ è§†é¢‘å–œçˆ±åº¦åˆ†æå®Œæˆï¼[/green]")
        logger.info(f"[green]æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“: {analyzer.db_path}[/green]")
        
    except Exception as e:
        logger.error(f"\n[red]âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}[/red]")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()